{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600d2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/07 11:05:47 WARN Utils: Your hostname, MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.69 instead (on interface en0)\n",
      "23/08/07 11:05:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/07 11:05:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import necessary libraries and create Spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"HousePricePrediction\").getOrCreate()\n",
    "\n",
    "\n",
    "# Cell 2: Read the data\n",
    "df_train = spark.read.csv(\"data/train.csv\", header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(\"data/test.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Cell 3: Drop unnecessary columns and handle missing values for \"MSZoning\" column\n",
    "cols_to_drop = ['FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC']\n",
    "df_train_cleaned = df_train.drop(*cols_to_drop)\n",
    "df_test_cleaned = df_test.drop(*cols_to_drop)\n",
    "\n",
    "mszoning_mode = df_train_cleaned.select(\"MSZoning\").groupBy(\"MSZoning\").count().orderBy(col(\"count\").desc()).first()[\"MSZoning\"]\n",
    "df_train_cleaned = df_train_cleaned.na.fill({\"MSZoning\": mszoning_mode})\n",
    "df_test_cleaned = df_test_cleaned.na.fill({\"MSZoning\": mszoning_mode})\n",
    "\n",
    "\n",
    "# Cell 4: Handle missing values for both categorical and numerical features\n",
    "categorical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\"]\n",
    "for col in categorical_cols:\n",
    "    mode_value = df_train_cleaned.select(col).groupBy(col).count().orderBy(col(\"count\").desc()).first()[col]\n",
    "    df_train_cleaned = df_train_cleaned.na.fill({col: mode_value})\n",
    "    df_test_cleaned = df_test_cleaned.na.fill({col: mode_value})\n",
    "\n",
    "numerical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\"]\n",
    "for col in numerical_cols:\n",
    "    df_train_cleaned = df_train_cleaned.withColumn(col, col(col).cast(\"double\"))\n",
    "    df_test_cleaned = df_test_cleaned.withColumn(col, col(col).cast(\"double\"))\n",
    "\n",
    "imputer = Imputer(inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "imputer_model = imputer.fit(df_train_cleaned)\n",
    "df_train_cleaned = imputer_model.transform(df_train_cleaned)\n",
    "df_test_cleaned = imputer_model.transform(df_test_cleaned)\n",
    "\n",
    "\n",
    "# Cell 5: Convert columns to the correct data types (after filling missing values for categorical columns)\n",
    "for col in df_train_cleaned.columns:\n",
    "    if col != \"Id\" and col != \"SalePrice\":\n",
    "        df_train_cleaned = df_train_cleaned.withColumn(col, col(col).cast(\"double\"))\n",
    "        df_test_cleaned = df_test_cleaned.withColumn(col, col(col).cast(\"double\"))\n",
    "\n",
    "\n",
    "# Cell 6: Drop columns with a high percentage of missing values\n",
    "missing_threshold = 0.8\n",
    "cols_to_drop = [col for col in df_train_cleaned.columns if (df_train_cleaned.select(col).na.drop().count() / df_train_cleaned.count()) < missing_threshold]\n",
    "df_train_cleaned = df_train_cleaned.drop(*cols_to_drop)\n",
    "df_test_cleaned = df_test_cleaned.drop(*cols_to_drop)\n",
    "\n",
    "\n",
    "# Cell 7: Feature Engineering and Transformation\n",
    "for col_name in [\"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\", \"GarageCars\", \"GarageArea\"]:\n",
    "    df_train_cleaned = df_train_cleaned.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "    df_test_cleaned = df_test_cleaned.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "\n",
    "categorical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\"]\n",
    "numerical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"numerical_features\")\n",
    "df_train_assembled = assembler.transform(df_train_cleaned)\n",
    "df_test_assembled = assembler.transform(df_test_cleaned)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"numerical_features\", outputCol=\"scaled_numerical_features\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df_train_assembled)\n",
    "df_train_scaled = scaler_model.transform(df_train_assembled)\n",
    "df_test_scaled = scaler_model.transform(df_test_assembled)\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid='keep') for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=f\"{indexer.getOutputCol()}_encoded\") for indexer in indexers]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df_train_encoded = pipeline.fit(df_train_scaled).transform(df_train_scaled)\n",
    "df_test_encoded = pipeline.fit(df_test_scaled).transform(df_test_scaled)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[f\"{col}_encoded\" for col in categorical_cols] + [\"scaled_numerical_features\"],\n",
    "                            outputCol=\"features\")\n",
    "df_train_final = assembler.transform(df_train_encoded)\n",
    "df_test_final = assembler.transform(df_test_encoded)\n",
    "\n",
    "df_train_final = df_train_final.select(\"Id\", \"features\", \"SalePrice\")\n",
    "df_test_final = df_test_final.select(\"Id\", \"features\")\n",
    "\n",
    "\n",
    "# Cell 8: Model Training and Evaluation using Cross-Validation\n",
    "# Split data into training and validation sets\n",
    "train_data, validation_data = df_train_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='SalePrice', maxIter=100, regParam=0.1)\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.5]).build()\n",
    "\n",
    "# Initialize CrossValidator\n",
    "evaluator = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Train the model using CrossValidator\n",
    "cvModel = cv.fit(train_data)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validation_predictions = cvModel.transform(validation_data)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "rmse = evaluator.evaluate(validation_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on validation data: {rmse:.2f}\")\n",
    "\n",
    "\n",
    "# Cell 9: Model Prediction on Test Data and Save Results\n",
    "# Make predictions on the test set\n",
    "test_predictions = cvModel.transform(df_test_final)\n",
    "\n",
    "# Select the necessary columns for the final result\n",
    "final_result = test_predictions.select(\"Id\", \"prediction\").withColumnRenamed(\"prediction\", \"SalePrice\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "final_result.coalesce(1).write.csv(\"predictions.csv\", header=True, mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
