{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600d2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/07 10:53:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import necessary libraries and create Spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Imputer\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"HousePricePrediction\").getOrCreate()\n",
    "\n",
    "\n",
    "# Cell 2: Read the data\n",
    "df_train = spark.read.csv(\"data/train.csv\", header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(\"data/test.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Cell 3: Drop unnecessary columns and handle missing values for \"MSZoning\" column\n",
    "cols_to_drop = ['FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC']\n",
    "df_train_cleaned = df_train.drop(*cols_to_drop)\n",
    "df_test_cleaned = df_test.drop(*cols_to_drop)\n",
    "\n",
    "mszoning_mode = df_train_cleaned.select(\"MSZoning\").groupBy(\"MSZoning\").count().orderBy(F.col(\"count\").desc()).first()[\"MSZoning\"]\n",
    "df_train_cleaned = df_train_cleaned.na.fill({\"MSZoning\": mszoning_mode})\n",
    "df_test_cleaned = df_test_cleaned.na.fill({\"MSZoning\": mszoning_mode})\n",
    "\n",
    "\n",
    "# Cell 4: Handle missing values for both categorical and numerical features\n",
    "\n",
    "# Handle missing values for categorical features\n",
    "categorical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\"]\n",
    "for col in categorical_cols:\n",
    "    mode_value = df_train_cleaned.select(col).groupBy(col).count().orderBy(F.col(\"count\").desc()).first()[col]\n",
    "    df_train_cleaned = df_train_cleaned.na.fill({col: mode_value})\n",
    "    df_test_cleaned = df_test_cleaned.na.fill({col: mode_value})\n",
    "\n",
    "# Handle missing values for numerical features\n",
    "numerical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\"]\n",
    "for col in numerical_cols:\n",
    "    df_train_cleaned = df_train_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "    df_test_cleaned = df_test_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "\n",
    "imputer = Imputer(inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "imputer_model = imputer.fit(df_train_cleaned)\n",
    "df_train_cleaned = imputer_model.transform(df_train_cleaned)\n",
    "df_test_cleaned = imputer_model.transform(df_test_cleaned)\n",
    "\n",
    "\n",
    "# Cell 5: Convert columns to the correct data types (after filling missing values for categorical columns)\n",
    "for col in df_train_cleaned.columns:\n",
    "    if col != \"Id\" and col != \"SalePrice\":\n",
    "        df_train_cleaned = df_train_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "        df_test_cleaned = df_test_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "\n",
    "\n",
    "# Cell 6: Data Cleaning and Preprocessing using pandas and scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "\n",
    "# Drop columns with a high percentage of missing values\n",
    "missing_threshold = 0.8\n",
    "cols_to_drop = [col for col in df_train.columns if (df_train.select(col).na.drop().count() / df_train.count()) < missing_threshold]\n",
    "df_train_cleaned = df_train.drop(*cols_to_drop)\n",
    "df_test_cleaned = df_test.drop(*cols_to_drop)\n",
    "\n",
    "# Fill missing numerical values with the mean\n",
    "numerical_cols_with_missing = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\" and df_train_cleaned.select(col_name).na.drop().count() != df_train_cleaned.count()]\n",
    "for col in numerical_cols_with_missing:\n",
    "    mean_value = df_train_cleaned.select(col).agg(avg(col)).collect()[0][0]\n",
    "    df_train_cleaned = df_train_cleaned.fillna(mean_value, subset=[col])\n",
    "    df_test_cleaned = df_test_cleaned.fillna(mean_value, subset=[col])\n",
    "\n",
    "# Fill missing categorical values with the most common value\n",
    "categorical_cols_with_missing = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\" and df_train_cleaned.select(col_name).na.drop().count() != df_train_cleaned.count()]\n",
    "for col in categorical_cols_with_missing:\n",
    "    most_common_value = df_train_cleaned.groupBy(col).count().orderBy(\"count\", ascending=False).first()[0]\n",
    "    df_train_cleaned = df_train_cleaned.fillna(most_common_value, subset=[col])\n",
    "    df_test_cleaned = df_test_cleaned.fillna(most_common_value, subset=[col])\n",
    "\n",
    "# Convert categorical columns to string type\n",
    "for col_name, dtype in df_train_cleaned.dtypes:\n",
    "    if dtype == \"string\":\n",
    "        df_train_cleaned = df_train_cleaned.withColumn(col_name, df_train_cleaned[col_name].cast(\"string\"))\n",
    "        df_test_cleaned = df_test_cleaned.withColumn(col_name, df_test_cleaned[col_name].cast(\"string\"))\n",
    "\n",
    "\n",
    "# Cell 7: Feature Engineering and Transformation\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "for col_name in [\"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\", \"GarageCars\", \"GarageArea\"]:\n",
    "    df_train_cleaned = df_train_cleaned.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "    df_test_cleaned = df_test_cleaned.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "\n",
    "# Feature engineering\n",
    "categorical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\"]\n",
    "numerical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\"]\n",
    "\n",
    "# Assemble the features\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"numerical_features\")\n",
    "df_train_assembled = assembler.transform(df_train_cleaned)\n",
    "df_test_assembled = assembler.transform(df_test_cleaned)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler(inputCol=\"numerical_features\", outputCol=\"scaled_numerical_features\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df_train_assembled)\n",
    "df_train_scaled = scaler_model.transform(df_train_assembled)\n",
    "df_test_scaled = scaler_model.transform(df_test_assembled)\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid='keep') for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=f\"{indexer.getOutputCol()}_encoded\") for indexer in indexers]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df_train_encoded = pipeline.fit(df_train_scaled).transform(df_train_scaled)\n",
    "df_test_encoded = pipeline.fit(df_test_scaled).transform(df_test_scaled)\n",
    "\n",
    "# Assemble all features\n",
    "assembler = VectorAssembler(inputCols=[f\"{col}_encoded\" for col in categorical_cols] + [\"scaled_numerical_features\"],\n",
    "                            outputCol=\"features\")\n",
    "df_train_final = assembler.transform(df_train_encoded)\n",
    "df_test_final = assembler.transform(df_test_encoded)\n",
    "\n",
    "# Select the final features for modeling\n",
    "df_train_final = df_train_final.select(\"Id\", \"features\", \"SalePrice\")\n",
    "df_test_final = df_test_final.select(\"Id\", \"features\")\n",
    "\n",
    "\n",
    "# Cell 8: Model Training and Evaluation using Cross-Validation\n",
    "# Split data into training and validation sets\n",
    "train_data, validation_data = df_train_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='SalePrice', maxIter=100, regParam=0.1)\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.5]).build()\n",
    "\n",
    "# Initialize CrossValidator\n",
    "evaluator = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Train the model using CrossValidator\n",
    "cvModel = cv.fit(train_data)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validation_predictions = cvModel.transform(validation_data)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "rmse = evaluator.evaluate(validation_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on validation data: {rmse:.2f}\")\n",
    "\n",
    "\n",
    "# Cell 9: Model Prediction on Test Data and Save Results\n",
    "# Make predictions on the test set\n",
    "test_predictions = cvModel.transform(df_test_final)\n",
    "\n",
    "# Select the necessary columns for the final result\n",
    "final_result = test_predictions.select(\"Id\", \"prediction\").withColumnRenamed(\"prediction\", \"SalePrice\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "final_result.coalesce(1).write.csv(\"predictions.csv\", header=True, mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
