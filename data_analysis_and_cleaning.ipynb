{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries and load the datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "\n",
    "# Load the train and test datasets\n",
    "df_train = pd.read_csv(\"/Users/nels.jacobson2/Desktop/Analytics_Class_Folder/Group-7-Project-4/Data/train.csv\")\n",
    "df_test = pd.read_csv(\"/Users/nels.jacobson2/Desktop/Analytics_Class_Folder/Group-7-Project-4/Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a870d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Display information about the train dataset\n",
    "# Display the first few rows of the train dataset\n",
    "print(\"Train Dataset has\", df_train.shape[0], \"Records/Rows and\", df_train.shape[1], \"attributes/columns.\")\n",
    "print(\"Test Dataset has\", df_test.shape[0], \"Records/Rows and\", df_test.shape[1], \"attributes/columns.\")\n",
    "df_train.head()\n",
    "\n",
    "# Information about the train dataset\n",
    "df_train.info(verbose=False)\n",
    "\n",
    "# Summary statistics for categorical columns in the train dataset\n",
    "df_train.describe(include=\"object\")\n",
    "\n",
    "# Summary statistics for numerical columns in the train dataset\n",
    "df_train.describe(include=[int, float])\n",
    "\n",
    "# Sample 5 rows from the train dataset\n",
    "df_train.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Cleaning and Handling Missing Values\n",
    "# Store test_id for future reference and drop the 'Id' column from both train and test datasets\n",
    "test_id = df_test[\"Id\"]\n",
    "df_train.drop(columns=\"Id\", inplace=True)\n",
    "df_test.drop(columns=\"Id\", inplace=True)\n",
    "\n",
    "# Check for missing values and calculate their percentage\n",
    "null_df = round(df_train.isnull().sum() / len(df_train) * 100, 2).sort_values().to_frame().rename(columns=\n",
    "                                                                                                  {0: \"Train % of Missing Values\"})\n",
    "null_df[\"Test % of Missing Values\"] = round(df_test.isnull().sum() / len(df_train) * 100, 2)\n",
    "\n",
    "# Display features with more than 45% missing values in either train or test dataset\n",
    "null_df[(null_df[\"Train % of Missing Values\"] > 45) | (null_df[\"Test % of Missing Values\"] > 45)]\n",
    "\n",
    "# Drop columns with more than 45% missing values from both train and test datasets\n",
    "cols_to_drop = [\"FireplaceQu\", \"Fence\", \"Alley\", \"MiscFeature\", \"PoolQC\"]\n",
    "df_train.drop(columns=cols_to_drop, inplace=True)\n",
    "df_test.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Separate the target variable \"SalePrice\" from the train dataset\n",
    "target = df_train[[\"SalePrice\"]].reset_index(drop=True)\n",
    "df_train.drop(columns=[\"SalePrice\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ffd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Concatenate the train and test datasets for data cleanup and analysis\n",
    "df = pd.concat([df_train, df_test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b3836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Handling Missing Values for Garage-related Features\n",
    "# Handle missing values for Garage-related features by filling with appropriate values\n",
    "garage_cols = [\"GarageYrBlt\", \"GarageArea\", \"GarageCars\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\"]\n",
    "for col in garage_cols:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col].fillna(\"None\", inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Handling Missing Values for Basement-related Features\n",
    "# Handle missing values for Basement-related features by filling with appropriate values\n",
    "basement_cols = [\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\"]\n",
    "for col in basement_cols:\n",
    "    df[col].fillna(\"None\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Handling Missing Values for Other Categorical Features\n",
    "# Handle missing values for MSZoning by filling with the mode of each MSSubClass category\n",
    "df['MSZoning'] = df.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Handle missing values for categorical columns by filling with the most frequent value\n",
    "cat_cols = ['Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Electrical', 'KitchenQual', 'Functional', 'SaleType']\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Handling Missing Values for LotFrontage\n",
    "# Handle missing values for LotFrontage by filling with the median value for each neighborhood\n",
    "df[\"LotFrontage\"] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5302d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Handling Missing Values for MasVnrArea, BsmtFinSF1, and BsmtFinSF2\n",
    "# Handle missing values for MasVnrArea, BsmtFinSF1, and BsmtFinSF2 by filling with the median value for each MasVnrType and BsmtFinType1, BsmtFinType2, respectively\n",
    "df[\"MasVnrArea\"] = df.groupby(\"MasVnrType\")[\"MasVnrArea\"].transform(lambda x: x.fillna(x.median()))\n",
    "df[\"BsmtFinSF1\"] = df.groupby(\"BsmtFinType1\")[\"BsmtFinSF1\"].transform(lambda x: x.fillna(x.median()))\n",
    "df[\"BsmtFinSF2\"] = df.groupby(\"BsmtFinType2\")[\"BsmtFinSF2\"].transform(lambda x: x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Handling Missing Values for BsmtFullBath and BsmtHalfBath\n",
    "# Handle missing values for BsmtFullBath and BsmtHalfBath by filling with 0\n",
    "df[\"BsmtFullBath\"].fillna(0, inplace=True)\n",
    "df[\"BsmtHalfBath\"].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14aa268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Creating a new feature 'TotalBsmtSF'\n",
    "# Create a new feature 'TotalBsmtSF' by summing BsmtFinSF1 and BsmtFinSF2\n",
    "df[\"TotalBsmtSF\"] = df[\"BsmtFinSF1\"] + df[\"BsmtFinSF2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Handling Missing Values for BsmtUnfSF\n",
    "# Handle missing values for BsmtUnfSF by filling with the median value\n",
    "df[\"BsmtUnfSF\"].fillna(df[\"BsmtUnfSF\"].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c07bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Check if there are any missing values left\n",
    "print(\"Total Missing Values Left is:\", df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Separate the train and test datasets after data cleanup\n",
    "df_train_cleaned = df.iloc[:len(df_train)].copy()\n",
    "df_test_cleaned = df.iloc[len(df_train):].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Data Analysis and Visualization\n",
    "# Visualize the distribution of the target variable \"SalePrice\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(target[\"SalePrice\"], kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of SalePrice\")\n",
    "plt.xlabel(\"SalePrice\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Check the skewness of the target variable \"SalePrice\"\n",
    "print(\"Skewness of SalePrice:\", target[\"SalePrice\"].skew())\n",
    "\n",
    "# Log-transform the target variable \"SalePrice\" to reduce skewness\n",
    "target[\"SalePrice\"] = np.log1p(target[\"SalePrice\"])\n",
    "\n",
    "# Check the skewness of the log-transformed target variable \"SalePrice\"\n",
    "print(\"Skewness of log-transformed SalePrice:\", target[\"SalePrice\"].skew())\n",
    "\n",
    "# Visualize the relationship between the overall quality ('OverallQual') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"OverallQual\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"OverallQual vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the above-ground living area square feet ('GrLivArea') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_train_cleaned[\"GrLivArea\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"GrLivArea vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the total rooms above grade ('TotRmsAbvGrd') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"TotRmsAbvGrd\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"TotRmsAbvGrd vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the garage area ('GarageArea') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_train_cleaned[\"GarageArea\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"GarageArea vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the year built ('YearBuilt') and the sale price\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"YearBuilt\"], y=target[\"SalePrice\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"YearBuilt vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the neighborhood ('Neighborhood') and the sale price\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"Neighborhood\"], y=target[\"SalePrice\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Neighborhood vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_train_cleaned.corr()\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
