{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries and load the datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Specify the relative path to the data directory\n",
    "data_dir = \"Group-7-Project-4/Data\"\n",
    "\n",
    "# Use os.path.join() to construct the absolute file paths\n",
    "train_csv_path = os.path.join(current_dir, data_dir, \"train.csv\")\n",
    "test_csv_path = os.path.join(current_dir, data_dir, \"test.csv\")\n",
    "\n",
    "# Load the datasets using the correct file paths\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "df_test = pd.read_csv(test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba211ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test datasets\n",
    "df_train = pd.read_csv(\"/Users/nels.jacobson2/Desktop/Analytics_Class_Folder/Group-7-Project-4/Data/train.csv\")\n",
    "df_test = pd.read_csv(\"/Users/nels.jacobson2/Desktop/Analytics_Class_Folder/Group-7-Project-4/Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af53b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Display information about the train dataset\n",
    "# Display the first few rows of the train dataset\n",
    "print(\"Train Dataset has\", df_train.shape[0], \"Records/Rows and\", df_train.shape[1], \"attributes/columns.\")\n",
    "print(\"Test Dataset has\", df_test.shape[0], \"Records/Rows and\", df_test.shape[1], \"attributes/columns.\")\n",
    "df_train.head()\n",
    "\n",
    "# Information about the train dataset\n",
    "df_train.info(verbose=False)\n",
    "\n",
    "# Summary statistics for categorical columns in the train dataset\n",
    "df_train.describe(include=\"object\")\n",
    "\n",
    "# Summary statistics for numerical columns in the train dataset\n",
    "df_train.describe(include=[int, float])\n",
    "\n",
    "# Sample 5 rows from the train dataset\n",
    "df_train.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Cleaning and Handling Missing Values\n",
    "# Store test_id for future reference and drop the 'Id' column from both train and test datasets\n",
    "test_id = df_test[\"Id\"]\n",
    "df_train.drop(columns=\"Id\", inplace=True)\n",
    "df_test.drop(columns=\"Id\", inplace=True)\n",
    "\n",
    "# Check for missing values and calculate their percentage\n",
    "null_df = round(df_train.isnull().sum() / len(df_train) * 100, 2).sort_values().to_frame().rename(columns=\n",
    "                                                                                                  {0: \"Train % of Missing Values\"})\n",
    "null_df[\"Test % of Missing Values\"] = round(df_test.isnull().sum() / len(df_train) * 100, 2)\n",
    "\n",
    "# Display features with more than 45% missing values in either train or test dataset\n",
    "null_df[(null_df[\"Train % of Missing Values\"] > 45) | (null_df[\"Test % of Missing Values\"] > 45)]\n",
    "\n",
    "# Drop columns with more than 45% missing values from both train and test datasets\n",
    "cols_to_drop = [\"FireplaceQu\", \"Fence\", \"Alley\", \"MiscFeature\", \"PoolQC\"]\n",
    "df_train.drop(columns=cols_to_drop, inplace=True)\n",
    "df_test.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Separate the target variable \"SalePrice\" from the train dataset\n",
    "target = df_train[[\"SalePrice\"]].reset_index(drop=True)\n",
    "df_train.drop(columns=[\"SalePrice\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad131802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Concatenate the train and test datasets for data cleanup and analysis\n",
    "df = pd.concat([df_train, df_test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Handling Missing Values for Garage-related Features\n",
    "# Handle missing values for Garage-related features by filling with appropriate values\n",
    "garage_cols = [\"GarageYrBlt\", \"GarageArea\", \"GarageCars\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\"]\n",
    "for col in garage_cols:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col].fillna(\"None\", inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Handling Missing Values for Basement-related Features\n",
    "# Handle missing values for Basement-related features by filling with appropriate values\n",
    "basement_cols = [\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\"]\n",
    "for col in basement_cols:\n",
    "    df[col].fillna(\"None\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aeee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Handling Missing Values for Other Categorical Features\n",
    "# Handle missing values for MSZoning by filling with the mode of each MSSubClass category\n",
    "df['MSZoning'] = df.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Handle missing values for categorical columns by filling with the most frequent value\n",
    "cat_cols = ['Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Electrical', 'KitchenQual', 'Functional', 'SaleType']\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Handling Missing Values for LotFrontage\n",
    "# Handle missing values for LotFrontage by filling with the median value for each neighborhood\n",
    "df[\"LotFrontage\"] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Handling Missing Values for MasVnrArea, BsmtFinSF1, and BsmtFinSF2\n",
    "# Handle missing values for MasVnrArea, BsmtFinSF1, and BsmtFinSF2 by filling with the median value for each MasVnrType and BsmtFinType1, BsmtFinType2, respectively\n",
    "df[\"MasVnrArea\"] = df.groupby(\"MasVnrType\")[\"MasVnrArea\"].transform(lambda x: x.fillna(x.median()))\n",
    "df[\"BsmtFinSF1\"] = df.groupby(\"BsmtFinType1\")[\"BsmtFinSF1\"].transform(lambda x: x.fillna(x.median()))\n",
    "df[\"BsmtFinSF2\"] = df.groupby(\"BsmtFinType2\")[\"BsmtFinSF2\"].transform(lambda x: x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Handling Missing Values for BsmtFullBath and BsmtHalfBath\n",
    "# Handle missing values for BsmtFullBath and BsmtHalfBath by filling with 0\n",
    "df[\"BsmtFullBath\"].fillna(0, inplace=True)\n",
    "df[\"BsmtHalfBath\"].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Creating a new feature 'TotalBsmtSF'\n",
    "# Create a new feature 'TotalBsmtSF' by summing BsmtFinSF1 and BsmtFinSF2\n",
    "df[\"TotalBsmtSF\"] = df[\"BsmtFinSF1\"] + df[\"BsmtFinSF2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Handling Missing Values for BsmtUnfSF\n",
    "# Handle missing values for BsmtUnfSF by filling with the median value\n",
    "df[\"BsmtUnfSF\"].fillna(df[\"BsmtUnfSF\"].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515999e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Check if there are any missing values left\n",
    "print(\"Total Missing Values Left is:\", df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2424992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Separate the train and test datasets after data cleanup\n",
    "df_train_cleaned = df.iloc[:len(df_train)].copy()\n",
    "df_test_cleaned = df.iloc[len(df_train):].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Data Analysis and Visualization\n",
    "# Visualize the distribution of the target variable \"SalePrice\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(target[\"SalePrice\"], kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of SalePrice\")\n",
    "plt.xlabel(\"SalePrice\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Check the skewness of the target variable \"SalePrice\"\n",
    "print(\"Skewness of SalePrice:\", target[\"SalePrice\"].skew())\n",
    "\n",
    "# Log-transform the target variable \"SalePrice\" to reduce skewness\n",
    "target[\"SalePrice\"] = np.log1p(target[\"SalePrice\"])\n",
    "\n",
    "# Check the skewness of the log-transformed target variable \"SalePrice\"\n",
    "print(\"Skewness of log-transformed SalePrice:\", target[\"SalePrice\"].skew())\n",
    "\n",
    "# Visualize the relationship between the overall quality ('OverallQual') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"OverallQual\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"OverallQual vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the above-ground living area square feet ('GrLivArea') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_train_cleaned[\"GrLivArea\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"GrLivArea vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the total rooms above grade ('TotRmsAbvGrd') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"TotRmsAbvGrd\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"TotRmsAbvGrd vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the garage area ('GarageArea') and the sale price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_train_cleaned[\"GarageArea\"], y=target[\"SalePrice\"])\n",
    "plt.title(\"GarageArea vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the year built ('YearBuilt') and the sale price\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"YearBuilt\"], y=target[\"SalePrice\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"YearBuilt vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between the neighborhood ('Neighborhood') and the sale price\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x=df_train_cleaned[\"Neighborhood\"], y=target[\"SalePrice\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Neighborhood vs. SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_train_cleaned.corr()\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aad444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Import necessary libraries for machine learning and split the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Assuming 'df_train_cleaned' is the cleaned train dataset and 'target' is the target variable\n",
    "# Separate the features and target variable\n",
    "X = df_train_cleaned.copy()  # No need to drop the target variable from the features\n",
    "y = target[\"SalePrice\"]\n",
    "\n",
    "# Perform one-hot encoding on categorical columns\n",
    "X = pd.get_dummies(X, drop_first=True)  # Use drop_first=True to avoid multicollinearity\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30134401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Create the Linear Regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Train the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Create the TensorFlow model\n",
    "tf_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer with no activation function for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "tf_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Train the TensorFlow model\n",
    "tf_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e589b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Evaluate the TensorFlow model\n",
    "tf_y_pred = tf_model.predict(X_test)\n",
    "tf_mse = mean_squared_error(y_test, tf_y_pred)\n",
    "tf_r_squared = r2_score(y_test, tf_y_pred)\n",
    "\n",
    "print(\"TensorFlow Model - Mean Squared Error:\", tf_mse)\n",
    "print(\"TensorFlow Model - R-squared:\", tf_r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1555d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Create the Keras model\n",
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer with no activation function for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "keras_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "keras_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79770ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: Train the Keras model\n",
    "keras_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035779d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 27: Evaluate the Keras model\n",
    "keras_y_pred = keras_model.predict(X_test)\n",
    "keras_mse = mean_squared_error(y_test, keras_y_pred)\n",
    "keras_r_squared = r2_score(y_test, keras_y_pred)\n",
    "\n",
    "print(\"Keras Model - Mean Squared Error:\", keras_mse)\n",
    "print(\"Keras Model - R-squared:\", keras_r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: Create and train the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_y_pred)\n",
    "xgb_r_squared = r2_score(y_test, xgb_y_pred)\n",
    "\n",
    "print(\"XGBoost Model - Mean Squared Error:\", xgb_mse)\n",
    "print(\"XGBoost Model - R-squared:\", xgb_r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37743e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Compare model performances\n",
    "print(\"Scikit-learn Linear Regression Model - Mean Squared Error:\", mse)\n",
    "print(\"Scikit-learn Linear Regression Model - R-squared:\", r_squared)\n",
    "\n",
    "print(\"TensorFlow Model - Mean Squared Error:\", tf_mse)\n",
    "print(\"TensorFlow Model - R-squared:\", tf_r_squared)\n",
    "\n",
    "print(\"Keras Model - Mean Squared Error:\", keras_mse)\n",
    "print(\"Keras Model - R-squared:\", keras_r_squared)\n",
    "\n",
    "print(\"XGBoost Model - Mean Squared Error:\", xgb_mse)\n",
    "print(\"XGBoost Model - R-squared:\", xgb_r_squared)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
