{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600d2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries and create Spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"HousePricePrediction\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286e64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Read the data\n",
    "df_train = spark.read.csv(\"data/train.csv\", header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(\"data/test.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bceab782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Drop unnecessary columns and handle missing values for \"MSZoning\" column\n",
    "cols_to_drop = ['FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC']\n",
    "df_train_cleaned = df_train.drop(*cols_to_drop)\n",
    "df_test_cleaned = df_test.drop(*cols_to_drop)\n",
    "\n",
    "mszoning_mode = df_train_cleaned.select(\"MSZoning\").groupBy(\"MSZoning\").count().orderBy(F.col(\"count\").desc()).first()[\"MSZoning\"]\n",
    "df_train_cleaned = df_train_cleaned.na.fill({\"MSZoning\": mszoning_mode})\n",
    "df_test_cleaned = df_test_cleaned.na.fill({\"MSZoning\": mszoning_mode})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a60eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Handle missing values for both categorical and numerical features\n",
    "\n",
    "# Handle missing values for categorical features\n",
    "categorical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\"]\n",
    "for col in categorical_cols:\n",
    "    mode_value = df_train_cleaned.select(col).groupBy(col).count().orderBy(F.col(\"count\").desc()).first()[col]\n",
    "    df_train_cleaned = df_train_cleaned.na.fill({col: mode_value})\n",
    "    df_test_cleaned = df_test_cleaned.na.fill({col: mode_value})\n",
    "\n",
    "# Handle missing values for numerical features\n",
    "numerical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\"]\n",
    "for col in numerical_cols:\n",
    "    df_train_cleaned = df_train_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "    df_test_cleaned = df_test_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "\n",
    "imputer = Imputer(inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "imputer_model = imputer.fit(df_train_cleaned)\n",
    "df_train_cleaned = imputer_model.transform(df_train_cleaned)\n",
    "df_test_cleaned = imputer_model.transform(df_test_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Convert columns to the correct data types (after filling missing values for categorical columns)\n",
    "for col in df_train_cleaned.columns:\n",
    "    if col != \"Id\" and col != \"SalePrice\":\n",
    "        df_train_cleaned = df_train_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n",
    "        df_test_cleaned = df_test_cleaned.withColumn(col, F.col(col).cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3402f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Data Cleaning and Preprocessing using pandas and scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "\n",
    "# Drop columns with a high percentage of missing values\n",
    "missing_threshold = 0.8\n",
    "cols_to_drop = [col for col in df_train.columns if (df_train.select(col).na.drop().count() / df_train.count()) < missing_threshold]\n",
    "df_train_cleaned = df_train.drop(*cols_to_drop)\n",
    "df_test_cleaned = df_test.drop(*cols_to_drop)\n",
    "\n",
    "# Fill missing numerical values with the mean\n",
    "numerical_cols_with_missing = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\" and df_train_cleaned.select(col_name).na.drop().count() != df_train_cleaned.count()]\n",
    "for col in numerical_cols_with_missing:\n",
    "    mean_value = df_train_cleaned.select(col).agg(avg(col)).collect()[0][0]\n",
    "    df_train_cleaned = df_train_cleaned.fillna(mean_value, subset=[col])\n",
    "    df_test_cleaned = df_test_cleaned.fillna(mean_value, subset=[col])\n",
    "\n",
    "# Fill missing categorical values with the most common value\n",
    "categorical_cols_with_missing = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\" and df_train_cleaned.select(col_name).na.drop().count() != df_train_cleaned.count()]\n",
    "for col in categorical_cols_with_missing:\n",
    "    most_common_value = df_train_cleaned.groupBy(col).count().orderBy(\"count\", ascending=False).first()[0]\n",
    "    df_train_cleaned = df_train_cleaned.fillna(most_common_value, subset=[col])\n",
    "    df_test_cleaned = df_test_cleaned.fillna(most_common_value, subset=[col])\n",
    "\n",
    "# Convert categorical columns to string type\n",
    "for col_name, dtype in df_train_cleaned.dtypes:\n",
    "    if dtype == \"string\":\n",
    "        df_train_cleaned = df_train_cleaned.withColumn(col_name, df_train_cleaned[col_name].cast(\"string\"))\n",
    "        df_test_cleaned = df_test_cleaned.withColumn(col_name, df_test_cleaned[col_name].cast(\"string\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed4faba0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "MSZoning_encoded does not exist. Available: Id, MSSubClass, MSZoning, LotFrontage, LotArea, Street, Alley, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearBuilt, YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, MasVnrArea, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, Heating, HeatingQC, CentralAir, Electrical, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, KitchenQual, TotRmsAbvGrd, Functional, Fireplaces, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond, PavedDrive, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, PoolQC, Fence, MiscFeature, MiscVal, MoSold, YrSold, SaleType, SaleCondition, SalePrice, numerical_features, scaled_numerical_features, MSZoning_index, LotFrontage_index, Street_index, Alley_index, LotShape_index, LandContour_index, Utilities_index, LotConfig_index, LandSlope_index, Neighborhood_index, Condition1_index, Condition2_index, BldgType_index, HouseStyle_index, RoofStyle_index, RoofMatl_index, Exterior1st_index, Exterior2nd_index, MasVnrType_index, MasVnrArea_index, ExterQual_index, ExterCond_index, Foundation_index, BsmtQual_index, BsmtCond_index, BsmtExposure_index, BsmtFinType1_index, BsmtFinType2_index, Heating_index, HeatingQC_index, CentralAir_index, Electrical_index, KitchenQual_index, Functional_index, FireplaceQu_index, GarageType_index, GarageYrBlt_index, GarageFinish_index, GarageQual_index, GarageCond_index, PavedDrive_index, PoolQC_index, Fence_index, MiscFeature_index, SaleType_index, SaleCondition_index, MSZoning_index_encoded, LotFrontage_index_encoded, Street_index_encoded, Alley_index_encoded, LotShape_index_encoded, LandContour_index_encoded, Utilities_index_encoded, LotConfig_index_encoded, LandSlope_index_encoded, Neighborhood_index_encoded, Condition1_index_encoded, Condition2_index_encoded, BldgType_index_encoded, HouseStyle_index_encoded, RoofStyle_index_encoded, RoofMatl_index_encoded, Exterior1st_index_encoded, Exterior2nd_index_encoded, MasVnrType_index_encoded, MasVnrArea_index_encoded, ExterQual_index_encoded, ExterCond_index_encoded, Foundation_index_encoded, BsmtQual_index_encoded, BsmtCond_index_encoded, BsmtExposure_index_encoded, BsmtFinType1_index_encoded, BsmtFinType2_index_encoded, Heating_index_encoded, HeatingQC_index_encoded, CentralAir_index_encoded, Electrical_index_encoded, KitchenQual_index_encoded, Functional_index_encoded, FireplaceQu_index_encoded, GarageType_index_encoded, GarageYrBlt_index_encoded, GarageFinish_index_encoded, GarageQual_index_encoded, GarageCond_index_encoded, PavedDrive_index_encoded, PoolQC_index_encoded, Fence_index_encoded, MiscFeature_index_encoded, SaleType_index_encoded, SaleCondition_index_encoded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rl/kx3s6v3x2xd0bdr07yj5mmkm0000gn/T/ipykernel_87720/1104999958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m assembler = VectorAssembler(inputCols=[f\"{col}_encoded\" for col in categorical_cols] + [\"scaled_numerical_features\"],\n\u001b[1;32m     37\u001b[0m                             outputCol=\"features\")\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdf_train_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mdf_test_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: MSZoning_encoded does not exist. Available: Id, MSSubClass, MSZoning, LotFrontage, LotArea, Street, Alley, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearBuilt, YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, MasVnrArea, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, Heating, HeatingQC, CentralAir, Electrical, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, KitchenQual, TotRmsAbvGrd, Functional, Fireplaces, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond, PavedDrive, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, PoolQC, Fence, MiscFeature, MiscVal, MoSold, YrSold, SaleType, SaleCondition, SalePrice, numerical_features, scaled_numerical_features, MSZoning_index, LotFrontage_index, Street_index, Alley_index, LotShape_index, LandContour_index, Utilities_index, LotConfig_index, LandSlope_index, Neighborhood_index, Condition1_index, Condition2_index, BldgType_index, HouseStyle_index, RoofStyle_index, RoofMatl_index, Exterior1st_index, Exterior2nd_index, MasVnrType_index, MasVnrArea_index, ExterQual_index, ExterCond_index, Foundation_index, BsmtQual_index, BsmtCond_index, BsmtExposure_index, BsmtFinType1_index, BsmtFinType2_index, Heating_index, HeatingQC_index, CentralAir_index, Electrical_index, KitchenQual_index, Functional_index, FireplaceQu_index, GarageType_index, GarageYrBlt_index, GarageFinish_index, GarageQual_index, GarageCond_index, PavedDrive_index, PoolQC_index, Fence_index, MiscFeature_index, SaleType_index, SaleCondition_index, MSZoning_index_encoded, LotFrontage_index_encoded, Street_index_encoded, Alley_index_encoded, LotShape_index_encoded, LandContour_index_encoded, Utilities_index_encoded, LotConfig_index_encoded, LandSlope_index_encoded, Neighborhood_index_encoded, Condition1_index_encoded, Condition2_index_encoded, BldgType_index_encoded, HouseStyle_index_encoded, RoofStyle_index_encoded, RoofMatl_index_encoded, Exterior1st_index_encoded, Exterior2nd_index_encoded, MasVnrType_index_encoded, MasVnrArea_index_encoded, ExterQual_index_encoded, ExterCond_index_encoded, Foundation_index_encoded, BsmtQual_index_encoded, BsmtCond_index_encoded, BsmtExposure_index_encoded, BsmtFinType1_index_encoded, BsmtFinType2_index_encoded, Heating_index_encoded, HeatingQC_index_encoded, CentralAir_index_encoded, Electrical_index_encoded, KitchenQual_index_encoded, Functional_index_encoded, FireplaceQu_index_encoded, GarageType_index_encoded, GarageYrBlt_index_encoded, GarageFinish_index_encoded, GarageQual_index_encoded, GarageCond_index_encoded, PavedDrive_index_encoded, PoolQC_index_encoded, Fence_index_encoded, MiscFeature_index_encoded, SaleType_index_encoded, SaleCondition_index_encoded"
     ]
    }
   ],
   "source": [
    "# Cell 7: Feature Engineering and Transformation\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "for col_name in [\"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\", \"GarageCars\", \"GarageArea\"]:\n",
    "    df_train_cleaned = df_train_cleaned.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "    df_test_cleaned = df_test_cleaned.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "\n",
    "# Feature engineering\n",
    "categorical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype == \"string\"]\n",
    "numerical_cols = [col_name for col_name, dtype in df_train_cleaned.dtypes if dtype != \"string\" and col_name != \"Id\" and col_name != \"SalePrice\"]\n",
    "\n",
    "# Assemble the features\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"numerical_features\")\n",
    "df_train_assembled = assembler.transform(df_train_cleaned)\n",
    "df_test_assembled = assembler.transform(df_test_cleaned)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler(inputCol=\"numerical_features\", outputCol=\"scaled_numerical_features\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df_train_assembled)\n",
    "df_train_scaled = scaler_model.transform(df_train_assembled)\n",
    "df_test_scaled = scaler_model.transform(df_test_assembled)\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid='keep') for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=f\"{indexer.getOutputCol()}_encoded\") for indexer in indexers]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df_train_encoded = pipeline.fit(df_train_scaled).transform(df_train_scaled)\n",
    "df_test_encoded = pipeline.fit(df_test_scaled).transform(df_test_scaled)\n",
    "\n",
    "# Assemble all features\n",
    "assembler = VectorAssembler(inputCols=[f\"{col}_encoded\" for col in categorical_cols] + [\"scaled_numerical_features\"],\n",
    "                            outputCol=\"features\")\n",
    "df_train_final = assembler.transform(df_train_encoded)\n",
    "df_test_final = assembler.transform(df_test_encoded)\n",
    "\n",
    "# Select the final features for modeling\n",
    "df_train_final = df_train_final.select(\"Id\", \"features\", \"SalePrice\")\n",
    "df_test_final = df_test_final.select(\"Id\", \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Model Training and Evaluation using Cross-Validation\n",
    "# Split data into training and validation sets\n",
    "train_data, validation_data = df_train_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='SalePrice', maxIter=100, regParam=0.1)\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.5]).build()\n",
    "\n",
    "# Initialize CrossValidator\n",
    "evaluator = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Train the model using CrossValidator\n",
    "cvModel = cv.fit(train_data)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validation_predictions = cvModel.transform(validation_data)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "rmse = evaluator.evaluate(validation_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on validation data: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model Prediction on Test Data and Save Results\n",
    "# Make predictions on the test set\n",
    "test_predictions = cvModel.transform(df_test_final)\n",
    "\n",
    "# Select the necessary columns for the final result\n",
    "final_result = test_predictions.select(\"Id\", \"prediction\").withColumnRenamed(\"prediction\", \"SalePrice\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "final_result.coalesce(1).write.csv(\"predictions.csv\", header=True, mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
